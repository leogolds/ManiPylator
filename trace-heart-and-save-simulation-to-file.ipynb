{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46eaf59e-e14f-4ac6-b756-1c646dbff0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import sleep \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import roboticstoolbox as rtb\n",
    "import spatialmath as sm\n",
    "\n",
    "from manipylator import VisualRobot\n",
    "from manipylator import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca545b5",
   "metadata": {},
   "source": [
    "# Load Robot\n",
    "Below we load a URDF file describing Manny the robot manipulator. A URDF is a textual representation of a robot, defining the parameters we need so we can calculate the forward & inverse kinemtics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a8d34c0-156a-44f3-b67a-0961e999172e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 07/04/25 01:22:21.877 33] [shell.py:_shell_pop_print@23] Graphical python shell detected, using wrapped sys.stdout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;159m[Genesis] [01:22:34] [INFO] \u001b[38;5;121m╭───────────────────────────────────────────────╮\u001b[0m\u001b[38;5;159m\u001b[0m\n",
      "\u001b[38;5;159m[Genesis] [01:22:34] [INFO] \u001b[38;5;121m│┈┉┈┉┈┉┈┉┈┉┈┉┈┉┈┉┈┉┈\u001b[0m\u001b[38;5;159m \u001b[38;5;121m\u001b[1m\u001b[3mGenesis\u001b[0m\u001b[38;5;159m \u001b[38;5;121m┈┉┈┉┈┉┈┉┈┉┈┉┈┉┈┉┈┉┈│\u001b[0m\u001b[38;5;159m\u001b[0m\n",
      "\u001b[38;5;159m[Genesis] [01:22:34] [INFO] \u001b[38;5;121m╰───────────────────────────────────────────────╯\u001b[0m\u001b[38;5;159m\u001b[0m\n",
      "\u001b[38;5;226m[Genesis] [01:22:34] [WARNING] No Intel XPU device available. Falling back to CPU for torch device.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;159m[Genesis] [01:22:35] [INFO] Consider setting 'performance_mode=True' in production to maximise runtime speed, if significantly increasing compilation time is not a concern.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RHI Error: Can not create Vulkan instance\n",
      "[W 07/04/25 01:22:35.710 33] [misc.py:adaptive_arch_select@758] Arch=[<Arch.vulkan: 10>] is not supported, falling back to CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;159m[Genesis] [01:22:37] [INFO] Running on \u001b[38;5;121m\u001b[4m[Intel(R) Core(TM) i7-8665U CPU @ 1.90GHz]\u001b[0m\u001b[38;5;159m with backend \u001b[38;5;121m\u001b[4mgs.cpu\u001b[0m\u001b[38;5;159m. Device memory: \u001b[38;5;121m\u001b[4m15.25\u001b[0m\u001b[38;5;159m GB.\u001b[0m\n",
      "\u001b[38;5;159m[Genesis] [01:22:37] [INFO] 🚀 Genesis initialized. 🔖 version: \u001b[38;5;121m\u001b[4m0.2.1\u001b[0m\u001b[38;5;159m, 🌱 seed: \u001b[38;5;121m\u001b[4mNone\u001b[0m\u001b[38;5;159m, 📏 precision: '\u001b[38;5;121m\u001b[4m32\u001b[0m\u001b[38;5;159m', 🐛 debug: \u001b[38;5;121m\u001b[4mFalse\u001b[0m\u001b[38;5;159m, 🎨 theme: '\u001b[38;5;121m\u001b[4mdark\u001b[0m\u001b[38;5;159m'.\u001b[0m\n",
      "\u001b[38;5;226m[Genesis] [01:22:37] [WARNING] Scene.show_FPS is deprecated. Please use Scene.profiling_options.show_FPS\u001b[0m\n",
      "\u001b[38;5;159m[Genesis] [01:22:37] [INFO] Scene \u001b[38;5;121m\u001b[3m<92b68e7>\u001b[0m\u001b[38;5;159m created.\u001b[0m\n",
      "\u001b[38;5;159m[Genesis] [01:22:37] [INFO] Adding \u001b[38;5;121m<gs.RigidEntity>\u001b[0m\u001b[38;5;159m. idx: \u001b[38;5;121m0\u001b[0m\u001b[38;5;159m, uid: \u001b[38;5;121m\u001b[3m<911be1f>\u001b[0m\u001b[38;5;159m, morph: \u001b[38;5;121m<gs.morphs.Plane>\u001b[0m\u001b[38;5;159m, material: \u001b[38;5;121m<gs.materials.Rigid>\u001b[0m\u001b[38;5;159m.\u001b[0m\n",
      "\u001b[38;5;159m[Genesis] [01:22:37] [INFO] Adding \u001b[38;5;121m<gs.RigidEntity>\u001b[0m\u001b[38;5;159m. idx: \u001b[38;5;121m1\u001b[0m\u001b[38;5;159m, uid: \u001b[38;5;121m\u001b[3m<25bf9c2>\u001b[0m\u001b[38;5;159m, morph: \u001b[38;5;121m<gs.morphs.URDF(file='/tmp/tmpcgxjp6a8.urdf')>\u001b[0m\u001b[38;5;159m, material: \u001b[38;5;121m<gs.materials.Rigid>\u001b[0m\u001b[38;5;159m.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Geom with duplicate name '' encountered in URDF, creating an unnamed geom.\n",
      "WARNING: Geom with duplicate name '' encountered in URDF, creating an unnamed geom.\n",
      "WARNING: Geom with duplicate name '' encountered in URDF, creating an unnamed geom.\n",
      "WARNING: Geom with duplicate name '' encountered in URDF, creating an unnamed geom.\n",
      "WARNING: Geom with duplicate name '' encountered in URDF, creating an unnamed geom.\n",
      "WARNING: Geom with duplicate name '' encountered in URDF, creating an unnamed geom.\n",
      "WARNING: Geom with duplicate name '' encountered in URDF, creating an unnamed geom.\n",
      "WARNING: Geom with duplicate name '' encountered in URDF, creating an unnamed geom.\n",
      "WARNING: Geom with duplicate name '' encountered in URDF, creating an unnamed geom.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;159m[Genesis] [01:22:41] [INFO] Falling back to legacy URDF parser. Default values of physics properties may be off.\u001b[0m\n",
      "\u001b[38;5;159m[Genesis] [01:22:41] [INFO] Applying offset to base link's pose with user provided value in morph.\u001b[0m\n",
      "\u001b[38;5;159m[Genesis] [01:22:52] [INFO] Building scene \u001b[38;5;121m\u001b[3m<92b68e7>\u001b[0m\u001b[38;5;159m...\u001b[0m\n",
      "\u001b[38;5;159m[Genesis] [01:23:32] [INFO] Compiling simulation kernels...\u001b[0m\n",
      "\u001b[38;5;159m[Genesis] [01:25:32] [INFO] Building visualizer...\u001b[0m\n",
      "\u001b[38;5;159m[Genesis] [01:25:46] [INFO] Viewer created. Resolution: \u001b[38;5;121m862×646\u001b[0m\u001b[38;5;159m, max_FPS: \u001b[38;5;121m60\u001b[0m\u001b[38;5;159m.\u001b[0m\n",
      "ERobot: measured, 6 joints (RRRRRR), dynamics, geometry, collision\n",
      "┌──────┬──────────────────┬───────┬──────────────────┬─────────────────────────────────────────────────────────────────────────────┐\n",
      "│ link │       link       │ joint │      parent      │                             ETS: parent to link                             │\n",
      "├──────┼──────────────────┼───────┼──────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "│    0 │ \u001b[38;5;4mbase\u001b[0m             │       │ BASE             │ SE3()                                                                       │\n",
      "│    1 │ carriage_1       │     0 │ base             │ SE3(-7.47e-06, -2.937e-06, 0.037; -180°, -7.914e-41°, -6.361e-15°) ⊕ Rz(q0) │\n",
      "│    2 │ shoulder_lift    │     1 │ carriage_1       │ SE3(-0.065, -2.469e-06, -0.055; 180°, 90°, 180°) ⊕ Rz(q1)                   │\n",
      "│    3 │ elbow            │     2 │ shoulder_lift    │ SE3(0.355, -2.338e-06, -4.032e-06; -180°, -3.45e-15°, 3.069e-12°) ⊕ Rz(q2)  │\n",
      "│    4 │ wrist_carriage_2 │     3 │ elbow            │ SE3(0.2755, -4.64e-11, -0.025; -180°, 1.041e-13°, -3.435e-12°) ⊕ Rz(q3)     │\n",
      "│    5 │ wrist_carriage_3 │     4 │ wrist_carriage_2 │ SE3(0.04001, 1.314e-07, -0.0485; -180°, -90°, 180°) ⊕ Rz(q4)                │\n",
      "│    6 │ @end_effector    │     5 │ wrist_carriage_3 │ SE3(-0.04, -2.317e-06, -0.0485; -90°, 9.732e-13°, -90°) ⊕ Rz(q5)            │\n",
      "└──────┴──────────────────┴───────┴──────────────────┴─────────────────────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with utils.render_robot_from_template(\"robots/empiric\") as robot_urdf:\n",
    "    manny = VisualRobot(robot_urdf)\n",
    "print(manny.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f20716c",
   "metadata": {},
   "source": [
    "# Simulating Manny\n",
    "Using the `manny.visualizer.robot` object we can get the properties of it's links. For example, a given link's location in 3D space. Below we find the location of the end effector in when the all joint parameters are set to 0 degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a7e816-58f9-488c-bde7-1041903dd26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = manny.visualizer.robot\n",
    "# robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb35f31b-70b4-4009-a132-610c43d3987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = robot.get_link('end_effector')\n",
    "# ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb155aa-0408-4d8d-acd0-720eff3f2fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2851e-01,  1.5981e-06,  8.1101e-01])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee_initial_pos = ee.get_pos()\n",
    "ee_initial_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71c870ea-7748-4cf6-b808-a03ea01f83c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.5000, 0.5000, 0.5000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee_initial_quat = ee.get_quat()\n",
    "ee_initial_quat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550734da",
   "metadata": {},
   "source": [
    "And we can verify that for the inverse is also true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8228776-a435-4b63-8925-717ff3c05637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 07/04/25 01:26:04.002 33] [frontend_ir.cpp:begin_frontend_struct_for_on_external_tensor@1694] ti.loop_config(serialize=True) does not have effect on the struct for. The execution order is not guaranteed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_qpos = robot.inverse_kinematics(\n",
    "    link = ee,\n",
    "    pos  = ee_initial_pos,\n",
    "    quat = ee_initial_quat,\n",
    ")\n",
    "initial_qpos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383e4556",
   "metadata": {},
   "source": [
    "I.e. that when setting all the joints to 0 degrees the end effector end up at `ee_initial_pos` and that if the end effector is at `ee_initial_pos` all the joints are at 0 degress.\n",
    "\n",
    "Similarly, for an arbitrary (reachable) location in 3D space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b781b329-82fd-48ec-824b-7070df97ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "qpos = robot.inverse_kinematics(\n",
    "    link = ee,\n",
    "    pos  = [-4.8500e-02, -4.7547e-02,  4.0200e-01],\n",
    "    quat = ee_initial_quat,\n",
    ")\n",
    "qpos\n",
    "\n",
    "# robot.set_dofs_position(qpos)\n",
    "# # print(robot.get_dofs_position())\n",
    "# manny.visualizer.scene.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4eaf17",
   "metadata": {},
   "source": [
    "# Tracing a Trajecotry in 3D Space\n",
    "Below we calculate a positions in R3 that correspond to a heart shaped curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dd60fb2b-98ba-4ac4-98a7-2ab3ca518f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12851399,  0.52847791,  0.1       ],\n",
       "       [-0.12847791,  0.52908029,  0.1       ],\n",
       "       [-0.12822709,  0.53086563,  0.1       ]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = 0.1\n",
    "offset = 0.3\n",
    "height = 0.1\n",
    "\n",
    "shape = utils.parametric_heart_1(np.linspace(0, 2*np.pi, 100))\n",
    "positions = scale * shape + offset\n",
    "# Shift the heart on the x axis so it's center intersects with when arm is at zero position\n",
    "positions[:,0] -= positions[0,0] - ee_initial_pos[0].numpy()\n",
    "# Shift in y so all positions have valid solutions\n",
    "positions[:,1] -= positions[1,0] - 0.1\n",
    "positions[:,2] = height\n",
    "\n",
    "positions[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19fd33e",
   "metadata": {},
   "source": [
    "Each row is the (x, y, z) coordinates of a point on the curve. This is useful if we'd like to visualize the expected path of the end effector in the viewer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "30c847bf-68e5-40d4-acf8-055309b043ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize in 2D\n",
    "# import pandas as pd\n",
    "# import hvplot.pandas\n",
    "\n",
    "# df = pd.DataFrame(positions, columns=['x', 'y', 'z'])\n",
    "# df.hvplot.scatter(x='x', y='y', aspect='equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d2535036-0279-4163-9bf7-6952d66217e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<genesis.ext.pyrender.mesh.Mesh at 0x75f53f5a6390>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize in 3D\n",
    "# manny.visualizer.scene.clear_debug_objects()\n",
    "manny.visualizer.scene.draw_debug_spheres(positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de1beac-c040-4728-ab31-330b984540a9",
   "metadata": {},
   "source": [
    "# Forward & Inverse Kinematics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad79ddbc",
   "metadata": {},
   "source": [
    "To simplify we can set the position of the arm to a reasonably close location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c98c09e6-5647-4bc2-93e1-df8441c8e8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0357,  0.2696,  0.2888])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot.set_dofs_position([0.2, 0.2, 2.35, 1, 1.57, 0])\n",
    "\n",
    "manny.visualizer.scene.step()\n",
    "ee.get_pos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b983c02e-10fd-4f15-ac80-56791098d89b",
   "metadata": {},
   "source": [
    "And calculate the joint parameters that will put the end-effector at the 0th point of the heart, with the end-effector pointing down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ed608db4-0516-41ab-bfc6-f49de36d2c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quat_pointing_down = [0, 0, 0, -1]\n",
    "\n",
    "initial_pose = robot.inverse_kinematics(\n",
    "        link = ee,\n",
    "        pos  = positions[0],\n",
    "        quat = quat_pointing_down,\n",
    "        )\n",
    "\n",
    "robot.set_dofs_position(initial_pose)\n",
    "manny.visualizer.scene.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "254418f5-ed57-416d-8db3-9140463f2ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset to zero pose\n",
    "# robot.set_dofs_position(initial_qpos)\n",
    "# manny.visualizer.scene.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a00fe6-0087-4e36-a735-e556229ebc28",
   "metadata": {},
   "source": [
    "Or we could calculate the inverse kinematics for all points in the trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "daa07f16-1b69-4f18-907b-90a082a743ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.0751, -0.8064,  1.5648,  0.8004,  1.5708, -3.2167]),\n",
       " tensor([-0.0749, -0.8075,  1.5621,  0.7988,  1.5708, -3.2165]),\n",
       " tensor([-0.0742, -0.8109,  1.5543,  0.7944,  1.5708, -3.2158]),\n",
       " tensor([-0.0726, -0.8161,  1.5420,  0.7873,  1.5708, -3.2142]),\n",
       " tensor([-0.0696, -0.8231,  1.5258,  0.7781,  1.5708, -3.2112])]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs = [robot.inverse_kinematics(\n",
    "        link = ee,\n",
    "        pos  = pos,\n",
    "        quat = quat_pointing_down,\n",
    "        ) for pos in positions]\n",
    "qs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e26f6c4-e712-4702-b8f3-a81353b1e58b",
   "metadata": {},
   "source": [
    "Using the above, we can simulate our solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3c21acce-304c-4af3-8881-64306d719139",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in qs:\n",
    "    robot.set_dofs_position(q)\n",
    "    # print(robot.get_dofs_position())\n",
    "    manny.visualizer.scene.step()\n",
    "    # camera.render()\n",
    "    sleep(0.1)\n",
    "\n",
    "# camera.stop_recording(save_to_filename='video.mp4', fps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5604c8-e0d8-4ba6-ba32-1465262ad432",
   "metadata": {},
   "source": [
    "Or save the simulation to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c2a733d3-78e0-48de-ae5e-7d6e4dddbba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;159m[Genesis] [02:13:23] [INFO] Saving video to \u001b[38;5;121mvideo.mp4\u001b[0m\u001b[38;5;159m.\u001b[0m\n",
      "\u001b[38;5;159m[Genesis] [02:13:32] [INFO] Video saved.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "camera = manny.visualizer.camera\n",
    "\n",
    "camera.start_recording()\n",
    "\n",
    "for q in qs:\n",
    "    robot.set_dofs_position(q)\n",
    "    # print(robot.get_dofs_position())\n",
    "    manny.visualizer.scene.step()\n",
    "    camera.render()\n",
    "    sleep(0.1)\n",
    "    \n",
    "# Reset to initial curve pose\n",
    "robot.set_dofs_position(qs[0])\n",
    "manny.visualizer.scene.step()\n",
    "camera.render()\n",
    "\n",
    "camera.stop_recording(save_to_filename='video.mp4', fps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11dfd2a",
   "metadata": {},
   "source": [
    "And to visualize the poses Manny would take, we can animate the path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a50e96d3-cd77-44e0-91ec-703eed77e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset to zero pose\n",
    "robot.set_dofs_position(initial_qpos)\n",
    "manny.visualizer.scene.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
